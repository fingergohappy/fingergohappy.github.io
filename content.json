{"posts":[{"title":"gitlab使用gitlab-runner进行cicd指引","text":"gitlab提供了强大的CI/CD功能，可以通过gitlab-runner来实现自动化构建、测试和部署。和其他CI/CD工具相比，gitlab的CI/CD功能集成度更高，使用起来也更方便。 下载安装gitlab-runnergitlab-runner和gitlab是分离的，gitlab-runner可以安装在任何服务器上，只要能访问到gitlab即可。 安装指南 配置gitlab-runner获取注册令牌项目设置 -&gt; CI/CD -&gt; Runner设置 -&gt; 注册令牌 注册gitlab-runner使用注册令牌注册runner,我这里注册两个,一个用于部署，一个用于编译。 123456789101112131415161718192021222324sudo gitlab-runner register \\ --non-interactive \\ --url &quot;your.gitlab-server.com&quot; \\ --registration-token &quot;token&quot; \\ --executor &quot;shell&quot; \\ --description &quot;shell-deploy-runner&quot; \\ --tag-list &quot;shell,deploy&quot; \\ --run-untagged=&quot;false&quot; \\ --locked=&quot;false&quot; \\ --tls-ca-file=&quot;&quot;sudo gitlab-runner register \\ --non-interactive \\ --url &quot;your.gitlab-server.com&quot; \\ --registration-token &quot;xxx&quot; \\ --executor &quot;docker&quot; \\ --docker-image &quot;node:20-alpine&quot; \\ --description &quot;docker-node-build-runner&quot; \\ --tag-list &quot;node-20&quot; \\ --run-untagged=&quot;true&quot; \\ --locked=&quot;false&quot; \\ --tls-ca-file=&quot;&quot; 参数说明: 非交互式注册123456--url: gitlab的地址--registration-token: 注册令牌--executor: 执行器类型，常用的有shell、docker等--description: runner的描述--tag-list: 标签列表，用逗号分隔,后面可以在流水线文件中指定使用哪个tag--docker-image: 如果使用docker执行器，需要指定docker镜像,优先级比较低,如果在流水线文件中指定了镜像,则使用流水线文件中的镜像 注册完成后,在刚刚ruuner页面即可看到 编写.gitlab-ci.yml在项目根目录下创建.gitlab-ci.yml文件,这是gitlab的流水线配置文件,可以参考官方文档。 实例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# 全局变量variables: PNPM_CACHE_DIR: &quot;.pnpm-store&quot; DEPLOY_PATH: &quot;/opt/dockerApps/nginx/html&quot; NPM_CONFIG_REGISTRY: &quot;http://192.168.1.11:8081/repository/io-npm-proxy/&quot; NPM_AUTH_USER: &quot;username&quot; NPM_AUTH_PASS: &quot;password&quot; NODE_TLS_REJECT_UNAUTHORIZED: &quot;0&quot; HUSKY: &quot;0&quot; HUSKY_SKIP_INSTALL: &quot;1&quot; DISABLE_HUSKY: &quot;1&quot; VITE_CDN: &quot;false&quot; NODE_OPTIONS: &quot;--max-old-space-size=8192&quot; CI: &quot;true&quot; GIT_SSL_NO_VERIFY: 1 GIT_STRATEGY: clonestages: - build - deploybuild: stage: build # 使用哪个镜像 image: gitlab-runner/node:20-alpine-build# 缓存配置,不能使用绝对路径,因为在docker中运行时,绝对路径会被映射到宿主机的路径 cache: key: ${CI_COMMIT_REF_SLUG} paths: - .pnpm-store/ - node_modules/# 使用哪个runner,这里使用上面注册的docker-node-build-runner tags: - node-20# 运行前的脚本 before_script: - corepack enable - corepack prepare pnpm@latest --activate - pnpm config set store-dir .pnpm-store - | echo &quot;registry=${NPM_CONFIG_REGISTRY} //192.168.1.11:8081/repository/io-npm-proxy/:_auth=$(echo -n ${NPM_AUTH_USER}:${NPM_AUTH_PASS} | base64) always-auth=true strict-ssl=false shamefully-hoist=true&quot; &gt; .npmrc# 运行脚本 script: # - pnpm install vite-plugin-cdn-import@1.0.1 --save-dev --ignore-scripts - pnpm install --frozen-lockfile --shamefully-hoist --ignore-scripts - pnpm run build# artifacts: 构建产物,这里指定了dist目录,可以在流水线页面下载 artifacts: paths: - dist/ expire_in: 1 week# 只有在指定的分支上运行 only: - test - dev-auto-deploydeploy: stage: deploy # 使用shell执行器的runner进行部署 tags: - shell - deploy script: - sudo mkdir -p ${DEPLOY_PATH} - ls dist/* - sudo cp -r dist/* ${DEPLOY_PATH}/ - sudo docker restart nasio_nginx dependencies: - build only: - main - dev-auto-deploy 说明结构说明这份yaml文件还是听见但得,主要包括stages、variables、jobs等部分。 冒号问题经过测试,貌似:在变量中会导致问题,所以在变量中不要使用:，可以使用其他符号代替或者通过单引号包裹起来。 镜像问题使用docker来构建时,每次都会重新创建一个容器,可以在运行gitlab-ruuner的机器上的/etc/gitlab-runner/config.toml中修改配置pull_policy = [&quot;if-not-present&quot;]，这样就不会每次都拉取镜像了。 1234567891011121314151617181920212223242526[[runners]] name = &quot;docker-node-build-runner&quot; url = &quot;https://dev.iotechina.com:6580/&quot; id = 58 token = &quot;us4ddKTyyP3yGbaVxcRz&quot; token_obtained_at = 2025-06-10T15:28:03Z token_expires_at = 0001-01-01T00:00:00Z executor = &quot;docker&quot; [runners.cache] MaxUploadedArchiveSize = 0 [runners.cache.s3] [runners.cache.gcs] [runners.cache.azure] [runners.docker] tls_verify = false image = &quot;node:20-alpine&quot; privileged = false disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false shm_size = 0 network_mtu = 0 # 设置缓存目录,将docker容器中的/cache目录映射到宿主机的/opt/gitlab-runner/cache目录 volumes = [&quot;/opt/gitlab-runner/cache:/cache:rw&quot;] # 只有在需要时才拉取镜像 pull_policy = [&quot;if-not-present&quot;] 修改之后重启gitlab-runner服务即可:gitlab-runner restart。 有时现有的镜像不满足需求，可以通过docker build命令构建一个新的镜像，然后在.gitlab-ci.yml中使用这个新镜像。如果国内网络环境下，可以考虑使用docker镜像 下载镜像可以使用命如下拉取镜像从而避免修改docker的配置文件。 1docker pull docker.1panel.live/library/node:20-alpine 构建产物传递在gitlab-ci中，构建产物可以通过artifacts来传递，指定需要传递的文件或目录。 上面的配置文件中可以看到,build阶段的artifacts部分指定了dist/目录，这样在构建完成后，dist/目录中的文件就可以在流水线页面下载。在deploy阶段中，通过dependencies指定了依赖于build阶段，这样就可以在部署阶段通过- sudo cp -r dist/* ${DEPLOY_PATH}/ 访问到build阶段的产物。","link":"/2025/06/11/gitlab-gitrunner-cicd-md/"},{"title":"gradle将spring-boot和vue打入一个jar包","text":"之前用maven搞过将spring-boot和vue打成一个jar包,现在的项目,我使用了gralde,又是同样的需求,使用gradle的composite似乎更优雅一些. 项目结构123456789.├── build.gradle.kts├── settings.gradle.kts├── app #spring-boot 目录│ ├── build.gradle.kts│ ├── settings.gradle.kts├── web #vue目录│ ├── build.gradle.kts│ ├── settings.gradle.kts 结构说明app和web分别为spring-boot和vue项目,就正常写就行,唯一不同的就是,vue项目里面添加一个gradle配置文件 配置文件说明需要改动的地方就只有web和最外面的项目的gradle的配置文件需要改动 web其中web的build.gradle.kts内容如下: 12345678910plugins{ base}tasks{ register&lt;Exec&gt;(&quot;build-dev&quot;){ workingDir(&quot;./&quot;) commandLine(&quot;pnpm&quot;,&quot;run&quot;,&quot;build:dev&quot;) }} 就是添加了一个打包任务 根目录根目录的gradle配置文件需要调整的地方比较多 setting.gradle.kts: 12345rootProject.name = &quot;example&quot;// 这里很重要,使用includeBuild完成组合构建includeBuild(&quot;./app&quot;)includeBuild(&quot;./web&quot;) build.gradle.kts: 123456789101112131415161718192021222324plugins { base}tasks{ register(&quot;build-all&quot;){ dependsOn(gradle.includedBuild(&quot;app&quot;).task(&quot;:classes&quot;)) dependsOn(gradle.includedBuild(&quot;web&quot;).task(&quot;:build-dev&quot;)) } register&lt;Copy&gt;(&quot;copy-static&quot;){ dependsOn(&quot;build-all&quot;) // gradle没有提供通过includeBuild直接获取build目录的api,只能这样写死 val webDistPath = gradle.includedBuild(&quot;web&quot;).projectDir.getPath() + &quot;/dist-dev&quot; val appClassesPath = gradle.includedBuild(&quot;app&quot;).projectDir.getPath() + &quot;/build/resources/main/static&quot; from(webDistPath){ include(&quot;*&quot;) } into(appClassesPath) } register(&quot;build-jar&quot;){ dependsOn(&quot;copy-static&quot;) dependsOn(gradle.includedBuild(&quot;app&quot;).task(&quot;:jar&quot;)) }} 这样执行gradle :build-jar,就会生成一个带有vue打包后的dist目录的jar包","link":"/2023/11/11/gradle-spring-boot-vue-one-jar/"},{"title":"gradle spring boot 打包无依赖jar","text":"背景希望spring-boot的jar包不包含项目的依赖,打包成一个轻量jar包,方便部署和快速打包 方法一:修改build.gradle.kts: 123456789101112tasks.withType&lt;Jar&gt;{ manifest { attributes[&quot;Main-Class&quot;] = &quot;com.io.alyze.AlyzeApplicationKt&quot; //添加所有依赖的 attributes[&quot;Class-Path&quot;] = configurations.runtimeClasspath.get().files.joinToString(&quot; &quot;) { &quot;./libs/${it.name}&quot; } }}tasks.register&lt;Copy&gt;(&quot;jar-dependency&quot;) { dependsOn(&quot;jar&quot;) from(configurations.runtimeClasspath) into(layout.buildDirectory.dir(&quot;libs/libs/&quot;))} 这样执行:./gradlew :jar-dependency 就会在build/lib目录生成一个xxx-palin.jar和一个libs文件夹 将这两个文件拷贝在一起,以使用java -jar xxx-plain.jar直接运行 方法二修改build.gradle.kts: 12345tasks.register&lt;Copy&gt;(&quot;jar-dependency&quot;) { dependsOn(&quot;jar&quot;) from(configurations.runtimeClasspath) into(layout.buildDirectory.dir(&quot;libs/libs/&quot;))} 这样执行:./gradlew :jar-dependency 就会在build/lib目录生成一个xxx-palin.jar和一个libs文件夹 将这两个文件拷贝在一起,可以使用java -cp &quot;alyze-1.0-plain.jar:libs/*&quot; your_main_class_name直接运行","link":"/2023/12/22/gradle-spring-boot-without-dependency/"},{"title":"hexo push后自动部署github pages","text":"hexo有几种部署方式,一种是本地编译后,直接push public路径下的静态文件,一种是通过cli方式,向仓库提交source下的的markdown文件,触发action.实现自动部署 本文主要说明后一种方式. 创建github workflow在hexo的根目录的.github/workflows/pages.yml路径下创建文件,文件内容: 12345678910111213141516171819202122232425262728293031323334353637383940name: Pageson: push: branches: - main # default branchjobs: pages: runs-on: ubuntu-latest permissions: contents: write steps: - uses: actions/checkout@v3 with: token: ${{ secrets.GITHUB_TOKEN }} # If your repository depends on submodule, please see: https://github.com/actions/checkout submodules: recursive - name: Use Node.js 16.x uses: actions/setup-node@v2 with: # 看下自己本地的noe版本 node-version: '16' - name: Cache NPM dependencies uses: actions/cache@v2 with: path: node_modules key: ${{ runner.OS }}-npm-cache restore-keys: | ${{ runner.OS }}-npm-cache - name: Install Dependencies run: npm install - name: Build run: npm run build - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 创建github pages参考 https://docs.github.com/en/pages/getting-started-with-github-pages/creating-a-github-pages-site 创建完成后,微调一下: 在settings-&gt;Pages-&gt;Build and deployment-&gt;Branch选项中,把branch改成gh-pages 初始化本地仓库1234git init .git remote add origin ${你上面创建的仓库地址}git remote add .git commit -m &quot;init project&quot; gitgnore由于使用了github的自动部署功能,所以无需上传静态文件,在hexo根目录添加.gitignore文件 123public/.deploy*/node_modules 提交最后提交到main分支 1git push -u origin main 提交完成后,在github的action选项中可以看到正在构建,构建完成,就可以在https://${your-username}.github.io路径访问你的在线博客了 参考https://hexo.io/docs/github-pages","link":"/2023/09/20/hexo-auto-deploy/"},{"title":"ganesha编译以及使用vscode开发ganesha","text":"简介如何手动编译ganesha以及如何使用vscode远程开发ganesha源码 FSAL层使用cephfs 环境远程环境服务器: centos 7cmake版本: 3.12.3vscode版本: 1.88.0 配置编译环境下载源代码ganesha地址 1git clone https://github.com/nfs-ganesha/nfs-ganesha 编译的同时还需要ntirpc这个包里面的头文件,所以还需要初始化子模块 1git submodule --recursive --init 安装cmake由于centos7自带的cmake版本过低,需要手动安装较新的版本 Download CMake from: https://cmake.org/download/1wget https://cmake.org/files/v3.12/cmake-3.12.3.tar.gz Compile from source and install12345tar zxvf cmake-3.*cd cmake-3.*./bootstrap --prefix=/usr/localmake -j$(nproc)make install Validate installation123cmake --versioncmake version *.*.*CMake suite maintained and supported by Kitware (kitware.com/cmake). 安装ganesha编译所需依赖包12345# Common things # libcpefs-devel libcephfs2 这两个是fsal层使用ceph时需要用到的包，libcephfs2这个包如果没有的话，cephfs的一些功能可能无法使用yum install gcc git cmake autoconf libtool bison flex libacl-devel libcephfs-devel libtirpc rpcbind# More nfs-ganesha specificyum install libgssglue-devel openssl-devel nfs-utils-lib-devel doxygen redhat-lsb gcc-c++ 编译在ganesha源码的同级文件夹新建一个build目录ganesha是使用cmake来控制编译FSAL哪个模块的,由于我们是编译cephfs这个模块，所以要我修改一下cmake的命令 123456789101112131415161718192021222324cd build# 执行构建cmake \\ -DUSE_FSAL_PROXY_V4=OFF \\ -DUSE_FSAL_PROXY_V3=OFF \\ -DUSE_FSAL_VFS=ON \\ -DUSE_FSAL_LUSTRE=OFF \\ -DUSE_FSAL_LIZARDFS=OFF \\ -DUSE_FSAL_KVSFS=OFF \\ -DUSE_FSAL_CEPH=ON \\ -DUSE_FSAL_GPFS=OFF \\ -DUSE_FSAL_XFS=OFF \\ -DUSE_FSAL_GLUSTER=OFF \\ -DUSE_FSAL_NULL=OFF \\ -DUSE_FSAL_RGW=OFF \\ -DUSE_FSAL_MEM=OFF \\ -DUSE_9P=OFF \\ ../nfs-ganesha/src# 编译cmake --build . 如果不出意外的话，在当前build目录下应该会出现一个ganesha.nfsd可执行文件 测试编译结果在build同级目录,新建一个test目录 将编译结果复制到test目录1cp ../build/ganesha.nfsd ./ 复制配置文件：1cp ../nfs-ganesha/src/config_samples/ceph.conf ./ 复制并link so文件(可选)由于是使用ceph作为ganesha的后端,需要复制编译好的so文件: 123456cp ../build/FSAL/FSAL_CEPH/libfsalceph.so ./mkdir -p /usr/lib64/ganesha/ln -s [path]/libfsalcephs.so /usr/lib64/ganesha/ 如果不想进行软连接，可以在配置文件中添加如下配置： 123456NFS_CORE_PARAM{ # 如果不想软连接so文件，可以进行如下配置 Plugins_Dir = &quot;./&quot;;} 修改一下配置文件如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225## It is possible to use FSAL_CEPH to provide an NFS gateway to CephFS. The# following sample config should be useful as a starting point for# configuration. This basic configuration is suitable for a standalone NFS# server, or an active/passive configuration managed by some sort of clustering# software (e.g. pacemaker, docker, etc.).## Note too that it is also possible to put a config file in RADOS, and give# ganesha a rados URL from which to fetch it. For instance, if the config# file is stored in a RADOS pool called &quot;nfs-ganesha&quot;, in a namespace called# &quot;ganesha-namespace&quot; with an object name of &quot;ganesha-config&quot;:## %url rados://nfs-ganesha/ganesha-namespace/ganesha-config## If we only export cephfs (or RGW), store the configs and recovery data in# RADOS, and mandate NFSv4.1+ for access, we can avoid any sort of local# storage, and ganesha can run as an unprivileged user (even inside a# locked-down container).#NFS_CORE_PARAM{ # Ganesha can lift the NFS grace period early if NLM is disabled. Enable_NLM = false; # rquotad doesn't add any value here. CephFS doesn't support per-uid # quotas anyway. Enable_RQUOTA = false; # In this configuration, we're just exporting NFSv4. In practice, it's # best to use NFSv4.1+ to get the benefit of sessions. Protocols = 4; # 如果不行，试试： # Protocols = 3,4,NFSv4,NFSv3; # NFS_Port = 8088; # 如果不想软连接so文件，可以进行如下配置 Plugins_Dir = &quot;./&quot;;}NFSv4{ # Modern versions of libcephfs have delegation support, though they # are not currently recommended in clustered configurations. They are # disabled by default but can be re-enabled for singleton or # active/passive configurations. # Delegations = false; # One can use any recovery backend with this configuration, but being # able to store it in RADOS is a nice feature that makes it easy to # migrate the daemon to another host. # # For a single-node or active/passive configuration, rados_ng driver # is preferred. For active/active clustered configurations, the # rados_cluster backend can be used instead. See the # ganesha-rados-grace manpage for more information. # RecoveryBackend = rados_ng; # NFSv4.0 clients do not send a RECLAIM_COMPLETE, so we end up having # to wait out the entire grace period if there are any. Avoid them. Minor_Versions = 1,2;}# The libcephfs client will aggressively cache information while it# can, so there is little benefit to ganesha actively caching the same# objects. Doing so can also hurt cache coherency. Here, we disable# as much attribute and directory caching as we can.MDCACHE { # Size the dirent cache down as small as possible. Dir_Chunk = 0;}EXPORT{ # Unique export ID number for this export Export_ID=100; # We're only interested in NFSv4 in this configuration Protocols = 4; # NFSv4 does not allow UDP transport Transports = TCP; # # Path into the cephfs tree. # # Note that FSAL_CEPH does not support subtree checking, so there is # no way to validate that a filehandle presented by a client is # reachable via an exported subtree. # # For that reason, we just export &quot;/&quot; here. Path = /; # # The pseudoroot path. This is where the export will appear in the # NFS pseudoroot namespace. # # Pseudo = /cephfs_a/; Pseudo = /cephfs_a; # We want to be able to read and write Access_Type = RW; # Time out attribute cache entries immediately Attr_Expiration_Time = 0; # Enable read delegations? libcephfs v13.0.1 and later allow the # ceph client to set a delegation. While it's possible to allow RW # delegations it's not recommended to enable them until ganesha # acquires CB_GETATTR support. # # Note too that delegations may not be safe in clustered # configurations, so it's probably best to just disable them until # this problem is resolved: # # http://tracker.ceph.com/issues/24802 # # Delegations = R; # NFS servers usually decide to &quot;squash&quot; incoming requests from the # root user to a &quot;nobody&quot; user. It's possible to disable that, but for # now, we leave it enabled. Squash = root; FSAL { # FSAL_CEPH export Name = CEPH; # # Ceph filesystems have a name string associated with them, and # modern versions of libcephfs can mount them based on the # name. The default is to mount the default filesystem in the # cluster (usually the first one created). # Filesystem = &quot;cephfs&quot;; # # Ceph clusters have their own authentication scheme (cephx). # Ganesha acts as a cephfs client. This is the client username # to use. This user will need to be created before running # ganesha. # # Typically ceph clients have a name like &quot;client.foo&quot;. This # setting should not contain the &quot;client.&quot; prefix. # # See: # # http://docs.ceph.com/docs/jewel/rados/operations/user-management/ # # The default is to set this to NULL, which means that the # userid is set to the default in libcephfs (which is # typically &quot;admin&quot;). # # User_Id = &quot;ganesha&quot;; # # Key to use for the session (if any). If not set, it uses the # normal search path for cephx keyring files to find a key: # # Secret_Access_Key = &quot;YOUR SECRET KEY HERE&quot;; }}# Config block for FSAL_CEPHCEPH{ # Path to a ceph.conf file for this ceph cluster. Ceph_Conf = /etc/ceph/ceph.conf; # User file-creation mask. These bits will be masked off from the unix # permissions on newly-created inodes. # umask = 0;}## This is the config block for the RADOS RecoveryBackend. This is only# used if you're storing the client recovery records in a RADOS object.#RADOS_KV{ # Path to a ceph.conf file for this cluster. # Ceph_Conf = /etc/ceph/ceph.conf; # The recoverybackend has its own ceph client. The default is to # let libcephfs autogenerate the userid. Note that RADOS_KV block does # not have a setting for Secret_Access_Key. A cephx keyring file must # be used for authenticated access. # UserId = &quot;ganesharecov&quot;; # Pool ID of the ceph storage pool that contains the recovery objects. # The default is &quot;nfs-ganesha&quot;. # pool = &quot;nfs-ganesha&quot;; pool = cephfs_data; # Consider setting a unique nodeid for each running daemon here, # particularly if this daemon could end up migrating to a host with # a different hostname (i.e. if you're running an active/passive cluster # with rados_ng/rados_kv and/or a scale-out rados_cluster). The default # is to use the hostname of the node where ganesha is running. # nodeid = hostname.example.com nodeid = node1;}# Config block for rados:// URL access. It too uses its own client to access# the object, separate from the FSAL_CEPH and RADOS_KV client.RADOS_URLS{ # Path to a ceph.conf file for this cluster. # Ceph_Conf = /etc/ceph/ceph.conf; # RADOS_URLS use their own ceph client too. Authenticated access # requires a cephx keyring file. # UserId = &quot;ganeshaurls&quot;; # We can also have ganesha watch a RADOS object for notifications, and # have it force a configuration reload when one comes in. Set this to # a valid rados:// URL to enable this feature. # watch_url = &quot;rados://pool/namespace/object&quot;;}# 日志LOG{ COMPONENTS{ ALL = FULL_DEBUG; }} 启动执行一下命令，如果不出意外的话就可以启动了：日志会输出在当前目录的log文件中 1./ganesha.nfsd -f ceph.conf -F -L log 挂载在另一台机器进行挂载: 1mount -t nfs -o nfsvers=4.1,proto=tcp &lt;ganesha-host-name&gt;:&lt;ganesha-pseudo-path&gt; &lt;mount-point&gt; 问题排查12345678# 查看进程ps -ef | grep ganesha# 查看是否启动端口lsof -i -P | grep ganeshanetstat -tnlp | grep ganesha# 查看否是有挂载点showmount vscode 配置远程开发下载插件Remote Development 配置免密登陆配置密钥如果没有ssh密钥，自行百度生成一份 1ssh-copy-id ${username}@${host} 配置ssh的config文件1vim ~/.ssh/config 添加一行配置： 12345678# 缩写Host ganesha # ip或者hostnameHostName 192.168.101.121Port 22PreferredAuthentications publickeyUser userIdentityFile ~/.ssh/id_rsa 连接配置上以上流程，这时打开vscode，cmd+shit+p就可以看到你要链接远程的机器 安装必要的插件以下插件都是在远程安装的 C/C++ CMake 配置vscodec_cpp_properties.json在.vscode目录下新建文件： c_cpp_properties.json 内容如下： 1234567891011121314151617181920{ &quot;configurations&quot;: [ { &quot;name&quot;: &quot;Linux&quot;, # 这里很重要，主要是配置那些路径被include进来，可以减少报错 &quot;includePath&quot;: [ &quot;${workspaceFolder}/build/include/**&quot;, &quot;${workspaceFolder}/src/**&quot;, &quot;/usr/include/**&quot;, &quot;/usr/include&quot; ], &quot;defines&quot;: [], &quot;compilerPath&quot;: &quot;/usr/bin/gcc&quot;, &quot;cStandard&quot;: &quot;c11&quot;, &quot;cppStandard&quot;: &quot;c++14&quot;, &quot;intelliSenseMode&quot;: &quot;${default}&quot; } ], &quot;version&quot;: 4} settings.json在.vscode目录下新建文件： settings.json 内容如下： 12345678910111213141516171819202122232425262728{ &quot;cmake.sourceDirectory&quot;: &quot;/root/nfs-ganesha-code/nfs-ganesha/src&quot;, &quot;cmake.options.statusBarVisibility&quot;: &quot;visible&quot;, &quot;files.associations&quot;: { &quot;config.h&quot;: &quot;c&quot;, &quot;nfs4.h&quot;: &quot;c&quot;, &quot;signal.h&quot;: &quot;c&quot;, &quot;internal.h&quot;: &quot;c&quot; }, &quot;C_Cpp.default.configurationProvider&quot;: &quot;ms-vscode.cmake-tools&quot;, # 这里就是控制编译那些选项 &quot;cmake.configureArgs&quot;: [ &quot;-DUSE_FSAL_PROXY_V4=OFF&quot;, &quot;-DUSE_FSAL_PROXY_V3=OFF&quot;, &quot;-DUSE_FSAL_VFS=OFF&quot;, &quot;-DUSE_FSAL_LUSTRE=OFF&quot;, &quot;-DUSE_FSAL_LIZARDFS=OFF&quot;, &quot;-DUSE_FSAL_KVSFS=OFF&quot;, &quot;-DUSE_FSAL_CEPH=ON&quot;, &quot;-DUSE_FSAL_GPFS=OFF&quot;, &quot;-DUSE_FSAL_XFS=OFF&quot;, &quot;-DUSE_FSAL_GLUSTER=OFF&quot;, &quot;-DUSE_FSAL_NULL=OFF&quot;, &quot;-DUSE_FSAL_RGW=OFF&quot;, &quot;-DUSE_FSAL_MEM=OFF&quot;, &quot;-DUSE_9P=OFF&quot; ]} 验证是否配置成功点击左侧的cmake插件，点击build,如果能成功的build,就是成功，如果不能，自行根据报错排查","link":"/2024/04/16/how-to-compile-ganesha/"},{"title":"手把手教你开发一个neovim插件","text":"开篇废话使用neovim久了,使用了众多插件,不自己开发一个插件,怎么好标榜自己是一个vimer?今天老夫就手把手教大家开发一个自己的neovim插件 项目结构与插件路径插件路径这里差不多也是废话,理论上来说,vim的插件可以在任何位置,插件的方式也可以是各种形式,不过为了这里面还是有一些潜规则的.首先就是插件的路径,一般来说,neovim会默认加载一些路径,可以在neovim中执行echo &amp;rtp(rtp:runtime path)来查看默认的加载路径有哪些,不过由于我们是自己开发的插件,就暂时不要放在这些路径里面了,避免启动时报错,假设我现在放在了~/temp/neovim/lua/lowb这个目录下进行开发lowb插件,然后在启动neovim的时候使用nvim --cmd &quot;set rtp+=~/temp/neovim&quot;启动就可以加载lowb插件了,插件名就是lua路径下的文件夹名,如果你的插件比较简单,可以不用新建一个文件夹,直接搞一个lowb.lua就可以加载了,不过按照约定一般是有一个文件夹的,方便发布,供其他人使用 这里需要注意,一定放在lua的子目录下,否则neovim是不会进行加载这个插件的,参考 项目结构init.luaneovim会自动加载目录下的init.lua作为neovim的默认加载文件 开始开发加载确定了插件路径和项目结构,就可以开发lowb插件了,在~/temp/neovim/lua/lowb,先新建一个init.lua文件,文件内容如下: 1print(&quot;Hello lowb&quot;) 然后使用nvim -c &quot;set rtp+=~/temp/neovim&quot;启动neovim 进入neovim的命令模式执行:lua require('lowb')可以看到会打印Hello lowbOK,现在插件成功加载了 导出函数插件肯定不能简单的加载,还要导出一些函数供用户使用,更新init.lua 123456local M = {}function M.say_lowb() print(&quot;hello lowb&quot;)endreturn M 保存插件,重新使用命令nvim -c &quot;set rtp+=~/temp/neovim&quot;启动neovim进入neovim的命令模式执行:lua require('lowb').say_lowb() 现在lowb插件基本完成,还有一项功能就是给用户设置的能力 setup函数neovim插件一般是通过向外暴露一个setup函数来给用户设定,这倒不是强制规定,只是一个默认约定,像一些插件管理工具,比如lazy.vim一般就是默认使用setup来进行初始化插件, 现在再改一下init.lua文件 12345678910111213141516171819local default_config = { name = &quot;狗蛋&quot;}local M = { config = default_config}function M.say_lowb() print(&quot;hello lowb &quot;..M.config.name)endfunction M.setup(config) M.config = config vim.print(M)endreturn M 保存退出,重新使用命令:nvim -c &quot;set rtp+=~/temp/neovim&quot; 启动neovim, 进入命令模式执行以下命令 12lua require('lowb').setup({name=finger})lua require('lowb').say_lowb() 就会看到打印的信息从”狗蛋”更新为”finger” 现在一个简单的neovim插件就开发完成了,至于能做什么 想象力越大,能力越大","link":"/2023/10/12/how-to-develope-a-neovim-plugin/"},{"title":"idea怎么在project 选项卡中隐藏特定的文件和文件夹","text":"在日常使用idea项目开发中,有些文件或者文件夹不想在project选项卡中显示,想要隐藏掉,隐藏方法: File -&gt; Settings -&gt; Editor -&gt; File Types -&gt; Ignore Files And folders","link":"/2023/10/13/idea-how-to-hide-folder-in-project/"},{"title":"idea下配置vim模式","text":"vim搓一切?有一说一,vim虽然可以配置的很舒服,但是对于java程序员来说,用vim去写java是真的折磨,除非你想进行自我折磨,变成代码仙人.所以最省心的方案就是在idea中下一个vim插件 安装首先你要有一个 java第一 IDE:intellij idea然后打开插件市场,下一个idea vimrc 安装上 配置.ideavimrc 创建一个~/.ideavimrc 加入一些配置: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156&quot; ____ _ ____ ___ ____&quot; | __ ) / \\ / ___| |_ _| / ___|&quot; | _ \\ / _ \\ \\___ \\ | | | |&quot; | |_) | / ___ \\ ___) | | | | |___&quot; |____/ /_/ \\_\\ |____/ |___| \\____|&quot; 上下预留5行set so=5&quot; 不折叠 set nowrap&quot; 去掉哔哔声set belloff=allset noerrorbellsset t_vb=set backspace=indent,eol,start whichwrap+=&lt;,&gt;,[,]&quot; Vim 的默认寄存器和系统剪贴板共享set clipboard+=unnamedplusset keep-english-in-normal&quot; 开启相对行set relativenumberset nuset ignorecaseset smartcase&quot; ____ _ _ _ ____ ___ _ _&quot; | _ \\ | | | | | | / ___| |_ _| | \\ | |&quot; | |_) | | | | | | | | | _ | | | \\| |&quot; | __/ | |___ | |_| | | |_| | | | | |\\ |&quot; |_| |_____| \\___/ \\____| |___| |_| \\_|&quot;&quot;&quot;开启多光标支持Plug 'machakann/vim-highlightedyank'Plug 'vim-scripts/argtextobj.vim'Plug 'justinmk/vim-sneak'Plug 'easymotion/vim-easymotion'Plug 'unblevable/quick-scope'Plug 'preservim/nerdtree'Plug 'tpope/vim-commentary'&quot;USAGE &quot; add surround&quot; ys{textobject motion}{indeifier}&quot; eg:&quot; ysiw'&quot;&quot; remove surround &quot; ds'&quot;&quot; change surround &quot; cs[(Plug &quot;tpope/vim-surround&quot;&quot;USAGE &quot; [count][&quot;x]gr{motion} Replace {motion} text with the contents of register x.&quot; Especially when using the unnamed register, this is&quot; quicker than &quot;_d{motion}P or &quot;_c{motion}&lt;C-R&gt;&quot;&quot; [count][&quot;x]grr Replace [count] lines with the contents of register x.&quot; To replace from the cursor position to the end of the&quot; line use [&quot;x]gr$&quot; {Visual}[&quot;x]gr Replace the selection with the contents of register x.&quot;Plug 'vim-scripts/ReplaceWithRegister'&quot; USAGE &quot; cx&quot; On the first use, define the first {motion} to exchange. On the second use, define the second {motion} and perform the exchange.&quot;&quot; cxx&quot; Like cx, but use the current line.&quot;&quot; X&quot; Like cx, but for Visual mode.&quot;&quot; cxc&quot; Clear any {motion} pending for exchange.&quot;Plug 'tommcdo/vim-exchange'Plug 'terryma/vim-multiple-cursors'&quot; quick-scop cofniglet g:qs_highlight_on_keys = ['f', 'F', 't', 'T']let g:qs_accepted_chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] &quot; https://github.com/JetBrains/ideavim/wiki/ideajoin-examplesset ideajoinset sneak&quot; _ __ _____ __ __ __ __ _ ____&quot; | |/ / | ____| \\ \\ / / | \\/ | / \\ | _ \\&quot; | ' / | _| \\ V / | |\\/| | / _ \\ | |_) |&quot; | . \\ | |___ | | | | | | / ___ \\ | __/&quot; |_|\\_\\ |_____| |_| |_| |_| /_/ \\_\\ |_|&quot; basic key map inoremap &lt;C-e&gt; &lt;END&gt;inoremap &lt;C-a&gt; &lt;HOME&gt;inoremap &lt;C-f&gt; &lt;Right&gt;inoremap &lt;C-b&gt; &lt;Left&gt;inoremap &lt;C-n&gt; &lt;Down&gt;inoremap &lt;C-p&gt; &lt;Up&gt;inoremap &lt;M-f&gt; &lt;S-Right&gt;inoremap &lt;M-b&gt; &lt;S-Left&gt;inoremap &lt;C-k&gt; &lt;ESC&gt;d$iinoremap &lt;C-d&gt; &lt;Del&gt;let mapleader=&quot; &quot;&quot; idea action confignnoremap gd &lt;Action&gt;(GotoDeclaration)nnoremap gi &lt;Action&gt;(GotoImplementation)nnoremap gs &lt;Action&gt;(GotoSuperMethod)nnoremap gt &lt;Action&gt;(GotoTypeDeclaration)map &lt;leader&gt;re &lt;Action&gt;(RenameElement)map &lt;leader&gt;gf &lt;Action&gt;(GotoFile)map &lt;leader&gt;gt &lt;Action&gt;(GotoSymbol)map &lt;leader&gt;f: &lt;Action&gt;(GotoAction)map &lt;leader&gt;f. &lt;Action&gt;(FindInPath)map &lt;leader&gt;fl &lt;Action&gt;(RecentLocations)map &lt;leader&gt;ff &lt;Action&gt;(RecentFiles)map &lt;leader&gt;et :NERDTreeToggle&lt;CR&gt;map &lt;leader&gt;ef :NERDTreeFocus&lt;CR&gt;map &lt;leader&gt;es &lt;Action&gt;(FileStructurePopup)nmap &lt;C-W&gt;q &lt;Action&gt;(CloseAllEditors)&quot; plugin config let g:multi_cursor_use_default_mapping=0&quot; Default mappinglet g:multi_cursor_start_word_key = '&lt;C-n&gt;'let g:multi_cursor_select_all_word_key = '&lt;A-n&gt;'let g:multi_cursor_start_key = 'g&lt;C-n&gt;'let g:multi_cursor_select_all_key = 'g&lt;A-n&gt;'let g:multi_cursor_next_key = '&lt;C-n&gt;'let g:multi_cursor_prev_key = '&lt;C-p&gt;'let g:multi_cursor_skip_key = '&lt;C-x&gt;'let g:multi_cursor_quit_key = '&lt;Esc&gt;' 让其生效打开idea,source一下 1source ~/.ideavimrc FBI WARNING .ideavimrc里面有一些插件是要在idea中也要下载对应的插件才能使用的,具体参考这里 map &lt;leader&gt;f: &lt;Action&gt;(GotoAction) 这种形式是在调用idea的原生功能,具体有哪些功能,可以参考这里,可以打开ideavim的插件,查看对应操作的&lt;ActionId&gt;","link":"/2023/09/22/intellij-idea-config-vim/"},{"title":"java byte array 转String在转回byte array不相等","text":"背景最近在搞微软的NBFS协议,这个协议实际上也是基于WebService,只不过对xml进行了压缩,按照他自己的编码规则进行压缩网上搜罗一圈后发现有个大佬写好的burp的NBFS插件WCF-Binary-SOAP-Plug-In这个插件会将传入的经过base64编码的xml转换成NBFS协议的base64编码的字符串 测试那边要使用jmeter对这个NBFS接口性能测试基本思路: 新建http request输入原始的xml 搞一个PreProcessor,调用大佬写的NBFS.exe获取压缩后的XMLbase64编码的字符串 PreProcessor 代码如下 12345678910111213141516171819import org.apache.commons.codec.binary.Base64;// 获取请求体数据def requestBody = sampler.getArguments().getArgument(0).getValue();// 检查请求体是否存在if (requestBody != null) { log.info(&quot;获取到请求体:{}&quot;,requestBody) // 进行加密操作，这里使用Base64编码作为示例 def reqBase64Str = Base64.encodeBase64String(requestBody.getBytes()); def process = Runtime.getRuntime().exec(&quot;./NBFS.exe&quot;,&quot;encode&quot;,reqBase64Str) process.waitFor() def nbfsEncodeBase64Str = process.inputStream.text def result = Base64.decodeBase64(nbfsEncodeBase64Str) // 将加密后的数据设置回请求体 sampler.getArguments().getArgument(0).setValue(new String(result));} else { log.warn(&quot;请求体不存在&quot;);} 这时候就会发现一个神奇的东西,接口会返回400错误 问题分析先说明下NBFS编码的原理,为了压缩xml,NBFS会预先定义一些字典,比如:0x90代表Reason这个字符,也就是说,经过NBFS.exe返回的Base64字符串经过Base64.decodeBase64(nbfsEncodeBase64Str)这个方法返回的byte数组中可能出现0x80,0xAA等字节 众所周知,java默认的字符串编码是UTF-8 另一个常识是:java字符串是由Char[]表示的,而Char是由unicode表示 ok,有了上面的已知条件,返回400的问题,就是解释为什么下面代码输出是false就行了 1234byte[] byteArray = new byte[]{0x01, (byte)0x81, (byte)0xAA, 0x44, 0x45};String str = new String(byteArray);byte [] revertByteArray = str.getBytes();System.out.println(Arrays.equals(byteArray,revertByteArray)); 其实断点调试下,会发现其实revertByteArray这个数组其实是:[1, -17, -65, -67, -17, -65, -67, 68, 69]而原数组是:[1, -128, -86, 68, 69]区别就是多出了6个byte,其中0x81,0xAA对应变成[-17,-65,-67],对应10进制的65533,对应的unicde就是:\\uFFFD 接下来就分析一下为什么0x81为什么会变成[-17,-65,-67]这玩意就行了 debug大法对new String(byteArr)这段代码开始debug,就会发现最终会进入一个超长的方法: sun.nio.cs.UTF_8.Decoder#decode: 123456789101112131415161718192021222324252627282930313233343536373839404142434445// da 就是字符串找保存的char[]// sa 就是String构造函数传进来的byte 数组// 就是这个方法将byte [] -&gt; char []// sp 是0,应该是偏移量, String str = new String(byteArray,1,1,&quot;UTF-8&quot;);这么创建字符串才会有,这个不重要,// len就是byte数组的长度public int decode(byte[] sa, int sp, int len, char[] da) { final int sl = sp + len; int dp = 0; int dlASCII = Math.min(len, da.length); ByteBuffer bb = null; // only necessary if malformed // ASCII only optimized loop //性能优化,&gt;= 0的意思就是byte没有溢出,也就是:0~128,对应就是0x00 到 0x00 0x80 while (dp &lt; dlASCII &amp;&amp; sa[sp] &gt;= 0) da[dp++] = (char) sa[sp++]; //下面就是范围判断,判断byte是否在utf8的编码范围内 while (sp &lt; sl) { int b1 = sa[sp++]; if (b1 &gt;= 0) { // 1 byte, 7 bits: 0xxxxxxx da[dp++] = (char) b1; } else if ((b1 &gt;&gt; 5) == -2 &amp;&amp; (b1 &amp; 0x1e) != 0) { // 2 bytes, 11 bits: 110xxxxx 10xxxxxx . . . } else if ((b1 &gt;&gt; 4) == -2) { // 3 bytes, 16 bits: 1110xxxx 10xxxxxx 10xxxxxx . . . } else if ((b1 &gt;&gt; 3) == -2) { // 4 bytes, 21 bits: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx . . . } else { if (malformedInputAction() != CodingErrorAction.REPLACE) return -1; da[dp++] = replacement().charAt(0); } } return dp; } 上面代码翻译成人话就是:循环byte数组里面的每一个byte 如果&gt;=0,就是ASCII 如果不是,判断是否符合条件: 1 byte, 7 bits: 0xxxxxxx 2 bytes, 11 bits: 110xxxxx 10xxxxxx 3 bytes, 16 bits: 1110xxxx 10xxxxxx 10xxxxxx 4 bytes, 21 bits: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 如果都不符合,就返回replacement()第0个char(打断点看,这个字符其实就是main类启动时创建的,其实这就是’65533’也就是\\uFFFD) 至此,真相大白 0x80-&gt;0b100000000x88-&gt;0b10010000 都不在上面的范围,所以他们最终的char最终都会变成65533(\\uFFFD) 其实上面的规则就是UTF-8规则,参考维基百科: 在ASCII码的范围，用一个字节表示，超出ASCII码的范围就用字节表示，这就形成了我们上面看到的UTF-8的表示方法，这样的好处是当UNICODE文件中只有ASCII码时，存储的文件都为一个字节，所以就是普通的ASCII文件无异，读取的时候也是如此，所以能与以前的ASCII文件兼容。 大于ASCII码的，就会由上面的第一字节的前几位表示该unicode字符的长度，比如110xxxxx前三位的二进制表示告诉我们这是个2BYTE的UNICODE字符；1110xxxx是个三位的UNICODE字符，依此类推；xxx的位置由字符编码数的二进制表示的位填入。越靠右的x具有越少的特殊意义。只用最短的那个足够表达一个字符编码数的多字节串。注意在多字节串中，第一个字节的开头”1”的数目就是整个串中字节的数目。 太长不看一句话总结:因为类似0x80,0x88等字节不在utf-8编码范围内,所以会返回一个默认字符,\\uFFFD(65533),这个字符占3个字节,所以就造成的两个byte数组不相等 解决方法解决方法很简单:找一个编码覆盖0x00 到 0xff,并且只用一个字节编码的编码格式就行,没错,就是你-ISO-8859-1! 所以下面代码输出就是true 123456byte[] byteArray = new byte[]{0x01, (byte)0x81, (byte)0xAA, 0x44, 0x45};String str = new String(byteArray,&quot;ISO-8859-1&quot;);byte [] revertByteArray = str.getBytes(&quot;ISO-8859-1&quot;);System.out.println(Arrays.equals(byteArray,revertByteArray));","link":"/2023/09/21/java-byte-convert-string-not-equal/"},{"title":"linux下安装多版本jdk并进行切换","text":"背景进行程序升级的时候,可能要在服务器上安装多个版本的jdk并且进行切换,我在本机使用的是asdf,这个东西用来管理多版本还是挺香的,不过由于服务器无法访问国际互联网,只能寻找其他替代方案. alternativesalternatives是linux系统中一个十分强大的命令(此句是废话,linux每个命令都很强大),主要功能就是为了解决,系统中有类似的命令,给用户一个选择的方式,在多个jdk的切换就很有用,可以在多个jdk版本切换 配置删除原来的内容如果你原来配置jdk方式是通过修改环境变量来实现的,要现去除掉这个配置,一般在/etc/profile或者/etc/environment或者~/.bash_profile这几个文件中,将原来的配置删除掉 12345# 全部注释掉#export JAVA_HOME=/var/local/jdk1.8.0_202#export JRE_HOME=${JAVA_HOME}/jre#export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib#export PATH=${JAVA_HOME}/bin:$PATH 然后执行source /etc/profile生效,如果不生效就重新登录下.这部完成后,再验证下,exho $PATH,看下java命令是不是在PATH中 使用laternatives配置jdk删除掉原来的配置后,就可以使用alternatives来配置java命令了,找到你两个jdk的位置,然后执行一下命令: 12345sudo alternatives --install /usr/bin/java java /opt/jdk1.8.0_301/bin/java 1sudo alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_301/bin/javac 1sudo alternatives --install /usr/bin/java java /opt/jdk-11.0.12/bin/java 2sudo alternatives --install /usr/bin/javac javac /opt/jdk-11.0.12/bin/javac 2 切换jdk后面如果想切换java版本,就可以使用命令: 12345678910$ alternatives --config javaThere are 2 programs which provide 'java'. Selection Command----------------------------------------------- 1 /var/local/jdk1.8.0_202/bin/java*+ 2 /usr/local/jdk-11/bin/javaEnter to keep the current selection[+], or type selection number: 输入一个序号就完成java版本的切换了","link":"/2024/01/05/linux-multi-jdk-config/"},{"title":"macos下,实现vim切换模式自动切换输入法","text":"macos下,实现vim切换模式自动切换输入法作为一个重度vim模式使用用户,切换模式输入法不自动切换一直是一个蛋疼的问题,目前主要解决方案就是使用im-select,在对应使用的应用里面设置im-select的路径但是这种方式有一个问题就是如果应用不支持,就不会自动切换 另一种方式就是使用rime输入法,但是对于我来说配置成本太高,不划算. 经过我的研究,发现karabiner可以实现在任意应用中使用vim,按下对应的模式切换键实现自动切换输入法. 安装karabinerkarabiner是mac下一个按键功能映射的软件,可以自己定义json文件实现许多复杂的功能的映射 brew不解释连招 1brew install karabiner 安装im-select继续brew不解释连招 1brew install im-select 创建映射文件/Users/fingerfrings/.config/karabiner/assets/complex_modifications路径创建一个vim-esc.json文件 文件内容如下: 123456789101112131415161718192021222324252627{ &quot;title&quot;: &quot;Vim shortcuts&quot;, &quot;rules&quot;: [ { &quot;description&quot;: &quot;Map ^+[ to esc&quot;, &quot;manipulators&quot;: [ { &quot;type&quot;: &quot;basic&quot;, &quot;from&quot;: { &quot;key_code&quot;: &quot;open_bracket&quot;, &quot;modifiers&quot;: { &quot;mandatory&quot;: [&quot;control&quot;] } }, &quot;to&quot;: [ { &quot;key_code&quot;: &quot;escape&quot; },{ &quot;shell_command&quot;: &quot;/usr/local/bin/im-select com.apple.keylayout.ABC&quot; } ] } ] }, ]} 上面文件的映射内容就是将Ctrl-[映射为Esc,同时执行/usr/local/bin/im-select com.apple.keylayout.ABC命令 设置karabiner在complex Modifications选项中启用Map ^+[ to esc 参考文档https://karabiner-elements.pqrs.org/docs","link":"/2023/09/20/macos-vim-auto-change-input-method/"},{"title":"Mysql配置主从同步","text":"Mysql 使用binlog配置主从同步 master 配置修改配置文件12345678910111213141516[mysqld]log-binserver-id=1replicate-do-db=tu-portal## 下面可选binlog_format=ROW #复制模式max_binlog_size=100M #超过max_binlog_size或超过6小时会切换到下一序号文件binlog_cache_size = 16Mlog_bin=/var/lib/mysql/mysql-bin.log #默认路径可修改expire_logs_days= 7 #日志过期时间，设置为0则永不过期binlog_cache_size=16M #二进制日志缓冲大小,通过show status like 'binlog_%';查看调整写入磁盘的次数，写入磁盘为0最好max_binlog_cache_size = 256Mrelay_log_recovery = 1 #当slave从库宕机后，假如relay-log损坏了，#导致一部分中继日志没有处理，则自动放弃所有未执行的relay-log，#并且重新从master上获取日志，这样就保证了relay-log的完整性。sync_binlog= 1 #二进制日志（binary log）同步到磁盘的频率innodb_flush_log_at_trx_commit = 1 #每次事务提交将日志缓冲区写入log file，并同时flush到磁盘。 创建从库用户1234CREATE USER 'slave1'@'127.0.0.1' IDENTIFIED BY 'qw1234';GRANT REPLICATION SLAVE ON *.* TO 'slave1'@'127.0.0.1';FLUSH PRIVILEGES; 对于8.4以上的版本,要么启用mysql_native_password插件，要么使用rsa认证我使用的启用mysql_native_password插件{.is-warning} 修改my.cnf 12[mysqld]mysql_native_password=ON 上面的创建用户的sql改为: 1234CREATE USER 'slave1'@'127.0.0.1' IDENTIFIED with mysql_native_password BY 'qw1234';GRANT REPLICATION SLAVE ON *.* TO 'slave1'@'127.0.0.1';FLUSH PRIVILEGES; dump主库数据12345# 给主库上锁FLUSH TABLES WITH READ LOCK;# dump数据mysqldump -uroot -pqw1234 --databases tu-portal -h 127.0.0.1 &gt; a.sql 查看主库状态记录File和Positon两个字段的值 123show master status;# 对于mysql 8.4 以上版本show binary log status; 释放锁12#释放锁UNLOCK TABLES; 配置从库修改从库配置文件修改从库配置文件： 12345[mysqld]log-binserver-id=2#replicate-do-db=tu-portal 重启数据库 向从库导入数据1nohup mysql -uroot -P 3307 -pqw1234 -h 127.0.0.1 &lt; ~/temp/mysql-master-slave/a.sql &amp; 配置salve123STOP SLAVE;CHANGE MASTER TO MASTER_HOST='192.168.33.22',MASTER_USER='slave1',MASTER_PASSWORD='slavepass',MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=613;START SLAVE; 对于8.4以上的版本 123STOP REPLICA;CHANGE REPLICATION SOURCE TO SOURCE_HOST='127.0.0.1',SOURCE_PORT=3306,SOURCE_USER='slave1',SOURCE_PASSWORD='qw1234',SOURCE_LOG_FILE='mysql-bin.000004',SOURCE_LOG_POS=459;START REPLCIA;","link":"/2024/05/07/mysql-config-master-slave/"},{"title":"neovim配置formatters","text":"最近再搞vue3,使用了element plus admin这个模版库,没想到一直报错后来经过排查发现是这个模板库使用了prettier这位lint的配置项,简单来说就是如果不符合他的格式就会报错,而我的neovim是使用的volar这个lsp作为格式化话的后端,想要保存自动安装prettier的格式格式化,需要额外加一些配置 本来是想打算用null-ls,因为更符合哲学的,其实就是将一些formatter作为neovim原生的lspinject进去不过这个项目目前停更了,而且我也只是想保存的时候格式化就行了,所以就选择了另一个插件formatter.nvim 安装安装prettier在mason中找到prettier安装就行不过这个地方比较有意思,mason其实是安装了prettier的,按时我在终端中缺无法使用,后来发现mason安装的工具其实是在~/.local/share/nvim/mason/bin/里面,然后在放到neovim内置的环境变量中是,在neovim的命令模式执行:!env就可以看到 安装formatter.nvim 12345678910111213141516171819202122{ &quot;mhartington/formatter.nvim&quot;, name = &quot;formatter&quot;, event = &quot;BufEnter&quot;, enabled = true, # 这个配置一定要写到config选项中,不然会报错 config = function(LazyPlugin,opts) local opts = { logging = true, log_level = vim.log.levels.WARN, filetype = { vue = { require(&quot;formatter.filetypes.vue&quot;).prettier(), _ } } } require(&quot;formatter&quot;).setup(opts) end } 这里需要注意的点是 formatter并没用给默认的格式化配置,所以没中文件都要配置 配置想要写到lazyvim的config选项中,不然会提示找不到formatter.filetypes.vue 保存自动格式化1vim.api.nvim_create_autocmd({&quot;BufWritePost&quot;},{pattern = {&quot;*&quot;},command = &quot;FormatWrite&quot;}) 原理formatter.nvim相当于一个接口,然后自己配置格式化命令,当执行格式化命令时,会调用你配置的格式化命令,如果不配置就是使用默认的,想上面的vue执行格式化的时候其实就是在执行默认的格式化,约等于下面的伪代码: 1prettier --stdin-filepath %","link":"/2023/11/01/neovim-config-formatter/"},{"title":"proxysql配置读写分离","text":"proxysql配置读写分离 配置mysql添加用户(如果使用已存在的用户,无需添加用户)12345-- 注意,这里的认证方式要使用mysql_native_passwordcreate user `proxysql` identified with mysql_native_password by 'proxysql-password';grant all privileges on proxysqldb.* to 'proxysql'@'%' identified with mysql_native_password by 'proxysql-password' 检查用户的认证方式1SELECT Host,User,plugin,authentication_string from mysql.user; 如果用户使用的不是mysql_native_password加密方式,需要修改一下加密方式: 12345drop user ${mysql_username}@'%';create user 'root'@'%' identified with mysql_native_password BY '${msqyl_password}';GRANT ALL PRIVILEGES ON *.* TO ${mysql_username}@'%' IDENTIFIED BY '${msqyl_password}' WITH GRANT OPTION; 检查autocommitproxysql的配置读写规则后,如果开启了事务,那么在commit之前都会走同一个库,举个例子:如果开启了autocommit.在执行玩commit之后,如果第一条语句是select,那么后面的所有语句都会走读库,包括insert和update语句.知道下一次commit为止. 所以要检查my.cnf里面的autocommit是否为off proxysql的基础配置连接proxysql在执行完systemctl restart proxysql之后,就可以使用mysql命令连接proxysql进行配置 1mysql -uadmin -padmin -h127.0.0.1 -P6032 分层说明官方文档 ┌─────────────────────────────────┐│ ││ Runtime ││ │└─────────────────────────────────┘ ┌─────────────────────────────────┐│ ││ Memory ││ │└─────────────────────────────────┘ ┌─────────────────────────────────┐│ ││ Disk &amp; Configuration File ││ │└─────────────────────────────────┘ 简单来说proxysql一共有3层,我们通过mysql客户端连接到proxysql进行配置后,是在Memory层进行操作,所有想使修改生效/持久化,要使用laod/save命令 global variables 配置表说明 修改proxysql提供的msyql服务的地址以及端口(可选)1234567-- 配置proxysql的mysql服务任意地址访问3306端口访问SET mysql-interfaces='0.0.0.0:3306';-- 注意修改这个变量要重启proxysql 服务SAVE MYSQL VARIABLES TO DISK;proxysql restart; 配置proxysql提供给应用的mysql版本号(可选)1234-- 根据你的应用要求以及后端数据库自行配置自行配置update global_variables set variable_value = '8.0.33' where variable_name = 'mysql-server_version';LOAD MYSQL VARIABLES TO RUNTIME;SAVE MYSQL VARIABLES TO DISK; 添加后端服务器表说明 12345INSERT INTO mysql_servers(hostgroup_id,hostname,port) VALUES (10,'10.0.0.1',3306);INSERT INTO mysql_servers(hostgroup_id,hostname,port) VALUES (20,'10.0.0.2',3306);load mysql servers to runtime;save mysql servers to disk; 配置监控监控的主要作用是监控后端服务器的健康状态表说明 1234567-- 根据你的定义自行修改set mysql-monitor_username=proxysqlusername;set mysql-monitor_password=proxysqlpasword;LOAD MYSQL VARIABLES TO RUNTIME;SAVE MYSQL VARIABLES TO DISK; 检查检查日志配置好监控和servers之后就可以查看监控日志了,如果error列为NULL,就是没有问题 12select * from monitor.mysql_server_connect_log order by time_start_us desc limit 3;select * from monitor.mysql_server_ping_log order by time_start_us desc limit 3; 配置分组信息表说明 1234-- 注意这里的writer_hostgroup和reader_hostgroup 要和上面的mysql_servers 里面的hostgroup_id对应上insert into mysql_replication_hostgroups(writer_hostgroup, reader_hostgroup, comment) values (10,20,'proxy');load mysql servers to runtime;save mysql servers to disk; 配置访问MYSQL的用户表说明 1234-- 根据你的配置自行修改INSERT INTO mysql_users(username,password,default_hostgroup) VALUES ('proxysql','proxysqlpassword',1);load mysql user to runtime;save mysql user to disk; 查看统计信息1show tables from stats; stats_mysql_connection_pool查看mysql后端的连接信息 stats_mysql_commands_counters查看各种sql语句分类的统计信息 stats_mysql_query_digest查看sql的digest的统计信息 配置读写分离proxysql默认所有的sql全部会走写库 proxysql默认不建议简单粗暴的将所有的select走读库,其他的操作走写库的配置,而是根据慢sql日志或者上面的stats_mysql_query_digest日志来进行配置 三种规则match digest正则匹配sql语句的digest text这里要先说明什么是sql的digest,就是将一个sql语句进行摘要,规则如下: 关键字大写 标识符都被加反引号` 常量包括数值常量和字符串常量都被替换成? 可以在任意mysql客户端查看一条sql语句的digest text: 12345678SELECT STATEMENT_DIGEST_TEXT('SELECT * FroM T1 WHERE c1 &gt; 10 and c2=&quot;abc&quot; AND 1+SIN(3) &gt; 0;') AS label;+------------------------------------------------------------------------+| label |+------------------------------------------------------------------------+| SELECT * FROM `T1` WHERE `c1` &gt; ? AND `c2` = ? AND ? + `SIN` (?) &gt; ? ; |+------------------------------------------------------------------------+1 row in set (0.00 sec) digestdigest就是将上面获得的digest text哈希运算后得到的hash字符串,可以在任意mysql客户端查看: 123456789101112131415mysql&gt; SELECT STATEMENT_DIGEST('SELECT * FROM T1 WHERE c1 &gt; 2;') AS label;+------------------------------------------------------------------+| label |+------------------------------------------------------------------+| 3e2db85c14a4bc5662e406bedb24bc3b47bc98ee99f28bba846e32980a09448d |+------------------------------------------------------------------+1 row in set (0.00 sec)mysql&gt; SELECT STATEMENT_DIGEST('SelecT * FROM T1 WHERE c1 &gt; 2;') AS label;+------------------------------------------------------------------+| label |+------------------------------------------------------------------+| 3e2db85c14a4bc5662e406bedb24bc3b47bc98ee99f28bba846e32980a09448d |+------------------------------------------------------------------+1 row in set (0.00 sec) match_pattern这个最好理解,就是sql语句的正则 mysql_query_rules表说明 根据mysql的慢sql查询或者上面的stats_mysql_query_digest表的统计信息结果,就可以配置读写规则了 1234567-- 注意这里只是例子,要根据场面的统计信息来进行配置然后在测试环境进行验证-- 注意这里的destination_hostgroup 要和 mysql_replication_hostgroups里面的对应上insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply) values (2,1,'^select.*for update$',10,1);insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply) values (3,1,'^select',20,1);load mysql query rules to runtime;save mysql query rules to disk; 检查是否sql执行是否遵循规则1select * from stats_mysql_query_digest; 参考文档How to configure ProxySQL for the first timeHow to set up ProxySQL Read/Write SplitMain (runtime tables definition)","link":"/2024/05/13/proxysql-config-read-write-spilt-md/"},{"title":"proxysql安装指引","text":"proxysql安装指引 下载proxysql进入proxysql的github releases下载最下rpm 安装在安装路径执行命令rpm -ivh proxy-sql.rpm执行安装,可能会缺少proxy-sql所需的依赖,根据情况安装即可 所需依赖可能需要安装的包,一下无需全部安装,根据上面命令输出,按需安装: gnutls perl-DBD-MySQL nettle perl-Compress-Raw-Bzip2 perl-Compress-Raw-Zlib perl-DBI perl-Data-Dumper perl-IO-Compress perl-Net-Daemon perl-PlRPC trousers 无网络安装 如果你的网络环境比较特殊,无法使用yum 安装,可以下载以上rpm包{.is-info} rpm可以去这个网站 然后执行命令 123456789101112rpm -ivh gnutls-3.3.29-9.el7_6.x86_64.rpm \\trousers-0.3.14-2.el7.x86_64.rpm \\nettle-2.7.1-8.el7.x86_64.rpm \\perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm \\perl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm \\perl-Net-Daemon-0.48-5.el7.noarch.rpm \\perl-IO-Compress-2.061-2.el7.noarch.rpm \\perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm \\perl-PlRPC-0.2020-14.el7.noarch.rpm \\perl-Data-Dumper-2.145-3.el7.x86_64.rpm \\perl-DBI-1.627-4.el7.x86_64.rpm \\perl-DBD-MySQL-4.023-6.el7.x86_64.rpm \\ 安装mysql客户端proxysql虽然底层的存储是文件和sqllite,但是proxysql重写了协议,可以使用mysql的客户端进行配置 1yum localinstall mysql80-community-release-el7-5.noarch.rpm &amp;&amp; yum -y install mysql-community-client 无网络安装如果你的服务器无法使用yum进行安装,可以下载对应的安装包,mysql客户端需要的rpm如下: mysql84-community-release-el7-1.noarch.rpm 下载地址 mysql-community-libs-8.3.0-1.el7.x86_64.rpm 下载地址 mysql-community-common-8.3.0-1.el7.x86_64.rpm 下载地址 mysql-community-client-plugins-8.3.0-1.el7.x86_64.rpm 下载地址 mysql-community-client-8.3.0-1.el7.x86_64.rpm 下载地址 执行命令: 123456rpm -ivh \\mysql84-community-release-el7-1.noarch.rpm \\mysql-community-libs-8.3.0-1.el7.x86_64.rpm \\mysql-community-common-8.3.0-1.el7.x86_64.rpm \\mysql-community-client-plugins-8.3.0-1.el7.x86_64.rpm \\mysql-community-client-8.3.0-1.el7.x86_64.rpm \\ 安装验证执行命令systemctl status proxysql 如果输出: 123Loaded: loaded (/etc/systemd/system/proxysql.service; enabled; vendor preset: disabled)Active: inactive (dead) 则证明安装成功 启动执行命令systemctl start proxysql 启动验证systemctl status proxysql如果输出: 12345678910111213141516● proxysql.service - High Performance Advanced Proxy for MySQL Loaded: loaded (/etc/systemd/system/proxysql.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2023-12-13 11:53:41 CST; 30s ago Process: 29610 ExecStart=/usr/bin/proxysql --idle-threads -c /etc/proxysql.cnf $PROXYSQL_OPTS (code=exited, status=0/SUCCESS) Main PID: 29612 (proxysql) CGroup: /system.slice/proxysql.service ├─29612 /usr/bin/proxysql --idle-threads -c /etc/proxysql.cnf └─29613 /usr/bin/proxysql --idle-threads -c /etc/proxysql.cnfDec 13 11:53:40 jira-node01 systemd[1]: Starting High Performance Advanced Proxy for MySQL...Dec 13 11:53:40 jira-node01 proxysql[29610]: 2023-12-13 11:53:40 [INFO] Using config file /etc/proxysql.cnfDec 13 11:53:40 jira-node01 proxysql[29610]: 2023-12-13 11:53:40 [INFO] Current RLIMIT_NOFILE: 102400Dec 13 11:53:40 jira-node01 proxysql[29610]: 2023-12-13 11:53:40 [INFO] Using OpenSSL version: OpenSSL 3.1.0 14 Mar 2023Dec 13 11:53:40 jira-node01 proxysql[29610]: 2023-12-13 11:53:40 [INFO] No SSL keys/certificates found in datadir (/var/lib/proxysql). Generating ne...ificates.Dec 13 11:53:41 jira-node01 systemd[1]: Started High Performance Advanced Proxy for MySQL. 则证明启动成功","link":"/2024/05/13/proxysql-install-guide-md/"},{"title":"管道操作符和xargs的区别","text":"之前一直没有理解shell中管道操作符和xargs的区别,为什么有一些命令要用可以直接用管道操作符链接,为什么一些需要加个xargs,最近翻了一些文档之后,终于理解 官方定义最好的解释永远来自于官方文档,正所谓真传一句话,假传万卷书. 管道操作符A pipeline is a sequence of one or more commands separated by one of the control operators ‘|’ or ‘|&amp;’.The output of each command in the pipeline is connected via a pipe to the input of the next command. That is, each command reads the previous command’s output. This connection is performed before any redirections specified by command1. 简单来说就是,管道操作符连接一系列命令,前面的标准输出作为后面的标准输入 xargsThe xargs utility reads space, tab, newline and end-of-file delimited strings from the standard input and executes utility with the strings as arguments.Any arguments specified on the command line are given to utility upon each invocation, followed by some number of the arguments read fromthe standard input of xargs. This is repeated until standard input is exhausted. Spaces, tabs and newlines may be embedded in arguments using single ( ' '') or double (“‘’) quotes or backslashes (``'‘). Singlequotes escape all non-single quote characters, excluding newlines, up to the matching single quote. Double quotes escape all non-doublequote characters, excluding newlines, up to the matching double quote. Any single character, including newlines, may be escaped by abackslash. 简单来说,就是xargs是从标准输入读取内容,作为xrags命令后面跟的命令的参数 举个例子管道操作符1echo &quot;hello \\n world&quot; | grep hello echo &quot;hello world&quot; 会将hello world字符串输出到标准输出,然后通过管道操作符作为 grep hello这条命令的标准输入 上面的命令相当于下面的命令 1234grep hello # 执行完按回车hello # 输入hello worldhello # 打印helloworld # 输入world 什么也不打印 xargs12xargs ls #按回车/usr #按ctrl-d 会打印/usr目录下的所有文件 ctrl-d相当于向shell输入了一个eof,表示输入完成 组合这两个命令一般是组合使用 比如: 1cat a.txt | xargs mkdir -p 这条命令的含义是,将a.ext文件中的内容作为文件夹名,新建一个文件夹其中,cat a.txt命令是将a.txt中的内容输出到标准输出,然后通过管道操作符作为xargs mkdir -p这个命令的标准输入,xargs将前面传过来的标准输入作为mkdir -p 这条命令的参数 标准输入/标准输出/参数在linux中,默认情况下 标准输入是指键盘标准输出是指屏幕参数就是命令后面跟着的内容 举个例子12345$ cat hello-world.txt # hello-world.txt 是参数$ cat #执行cat命令后回车$ hello #输入hello 这里的hello就是标准输入$ hello # 命令行打印hello 这里打印的hello就是找女友输入","link":"/2023/10/31/shell-pipeline-and-xargs/"},{"title":"终端下常用快捷键汇总","text":"说明其实大部分都是emacs的快捷键,终端也可以切换为vim模式,快捷键就会有变化 C : CtrlA : ALT 光标移动 快捷键 效果 C-a 移动到行首 C-e 移动到行尾 C-f 向后移动一个字符 C-b 向前移动一个字符 C-xx 在行首和当前光标位置之间互相切换 A-f / ESC-f 向后移动一个单词 A-b / ESC-b 向前移动一个单词 控制和处理流程 快捷键 效果 C-l 清除命令行历史输出 C-z 挂起当前程序 C-q 回复挂起的程序 C-i 等于tab C-j 等于enter 编辑 快捷键 效果 C-d 删除后一个字符 C-h 删除光标钱一个字符 C-k 从光标删除到行尾 C-u 从光标删除到行首 C-w 删除光标前的一个单词 A-t / Esc-t 替换当前光标的单词和前一个单词的位置 历史相关的 快捷键 效果 C-r 搜索历史 C-p 上一条命令 C-n 下一条命令","link":"/2023/09/24/terminal-shortcuts/"},{"title":"tls加密简介","text":"啥是tls加密，啥是非对称加密，啥是对称加密，啥是数字签名，啥是证书，这些都是什么鬼？ 使用openssl 生成证书如何使用openssl生成证书，这里以生成自签名证书为例。 1234567891011121314151617181920212223242526272829# 生成ca私钥openssl genpkey -algorithm RSA -out ca.key -aes256# 生成自签名根证书openssl req -x509 -new -nodes -key ca.key -sha256 -days 3650 -out ca.crt# 生成服务器私钥openssl genpkey -algorithm RSA -out server.key -aes256# 生成证书签名请求（CSR）openssl req -new -key server.key -out server.csr# 使用ca证书签名服务器证书openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 3650 -sha256# 生成客户端私钥openssl genpkey -algorithm RSA -out client.key# 生成客户端证书签名请求 (CSR)openssl req -new -key client.key -out client.csr# 使用ca证书签名客户端证书openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365 -sha256# 生成客户端p12证书openssl pkcs12 -export -out client.p12 -inkey client.key -in client.crt -certfile ca.crt 对称加密和非对称加密对称加密加密和解密都是用的同一个密钥，这个密钥就是对称加密的密钥。 表现形式就是: client : content –&gt; (key) –&gt; encrypted contentserver : encrypted content –&gt; (key) –&gt; content 非对称加密:加密和解密使用不同的密钥，一个是公钥，一个是私钥。一般来说,公钥用来加密,私钥用来解密。 表现形式就是: client : content –&gt; (public key) –&gt; encrypted contentserver : encrypted content –&gt; (private key) –&gt; content 为什么使用非对称加密只要涉及到密钥的传输，就会有密钥泄露的风险，而非对称加密就是为了解决这个问题的。对称加密的密钥是需要传输的，而非对称加密的公钥是可以公开的，私钥是不会传输的，这样就解决了密钥传输的问题。 然后这会出现一个问题，就是如何保证公钥的真实性，这就需要数字签名和证书了。 证书和数字签名因为要在网络上传输公钥，所以需要保证公钥的真实性，这就需要证书和数字签名。证书就是一个包含了公钥和一些其他信息的文件，数字签名就是用来保证证书的真实性的。因为非对称加密也要传输公钥,避免中间人攻击(大概原理就是:坏人A假装是服务器,把公钥发给客户端,那么客户端就会把信息发送给坏人A),所以公钥都是要通过数字证书认证的. 也就是上面生成证书的这一步: 1openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365 -sha256 这个ca证书由大家公认的证书机构颁发，这个证书机构就是CA(Certificate Authority)。 也就是客户端在收到服务器的公钥后，会验证这个公钥是否是CA颁发的，如果是的话，就可以信任这个公钥。 证书和公钥的关系需要注意的是，证书是包含了公钥的，但是证书不等于公钥，证书是包含了公钥的，还有一些其他信息的文件，比如证书的颁发者，证书的有效期等等。也就是说证书是包含公钥的. X.509因为证书不仅包含公钥,还包含其他信息,所以就必须有一个标准来定义证书的格式.X.509就是这样一个标准。在上面生成证书的时候，使用的是x509的标准，这个标准是用来定义证书的格式的。 简单说,X.509就是一个证书的标准.定义了证书的数据结构.比如第几个字节代表什么,这个字段是什么等等. 什么是双向认证,什么是单向认证单向认证就是客户端值验证服务器的证书，服务器不验证客户端的证书。 https就是单向认证。 双向认证服务端验证客户端的证书，客户端验证服务端的证书。 这种情况下，客户端也需要有证书，这个证书是由CA颁发的，这个证书就是上面生成的client.crt。 非对称加密和TLS双向认证TLS是基于非对称加密的，TLS的握手过程就是用来协商对称加密的密钥的。过程如下(只展示证书参与的过程): clien –connect–&gt; server : connectserver –server crt –&gt; client : 服务端向客户端出示证书,客户端使用ca证书验证服务端证书client –client crt –&gt; server : 客户端向服务端出示证书,服务端使用ca证书验证客户端证书 常用文件格式解释:在生成证书的过程,网上可能会有很多文件格式.这里回忆下每一步生成的过程.以自签名证书为例: 生成ca私钥–&gt; ca.key 生成自签名根证书 –&gt; ca.crt 生成服务器私钥 –&gt; server.key 生成证书签名请求(CSR) –&gt; server.csr 使用ca证书签名服务器证书 –&gt; server.crt…. 省略客户端密钥和公钥生成的过程 key,pem,der,p12,PCSK#7 ……网上不同的文章可能生成各种文件.也可能描述的不一样.这里简单解释下. pemPrivacy Enhanced Mail， 一般为文本格式，以 —–BEGIN… 开头，以 —–END… 结尾。中间的内容是 BASE64 编码。这种格式即可以保存私钥也可以保存证书，有时我们也把PEM 格式的私钥的后缀改为 .key 以区别证书与私钥。具体你可以看文件的内容。 pem强调的是文件的格式,而不是文件的内容. 比如.crt,.csr,.key都是pem格式的文件. der,crt,cer都是基于X.509标准的证书格式,只是后缀和格式不一样. der是二进制格式,而crt和cer是文本格式. 只包含一个证书 PKCS#7,PKCS#12和pem区别PKCS说的是一种数据结构,是以二进制编码格式保存的.而pem是一种编码格式.两者可以互相转换. PKCS#7保存证书的另一种格式,这种格式可以保存多个证书,比如证书链. PKCS#12包含私钥和证书的格式,这种格式一般用来保存客户端的私钥和证书,这样方便客户端使用.一般有密码保护一般以.p12结尾. csrCertificate Signing Request，证书签名请求. CSR 包含的内容： 公钥：CSR中包含的是你生成的密钥对中的公钥（不包括私钥）。CA会用这个公钥来生成证书。 标识信息：CSR还包含请求者的相关信息，如组织名、域名、国家等。这些信息最终会出现在证书中。 签名：CSR文件由请求者使用自己的私钥对请求进行签名，保证请求的真实性和公钥的合法性。 csr只有经过ca签名后才能生成crt证书. key私钥,私钥和公钥是成对的,私钥保存在key中,而公钥保存在crt或者csr中. crtCertificate 的简称，有可能是 PEM 编码格式，也有可能是 DER 编码格式证书,里面包含了公钥和其他信息,比如证书的颁发者,证书的有效期等等. 总结之前看生成证书的过程,会有生成很多文件,而且不同文章生成的文件后缀不一样,让我一直不理解. 其实生成自签名证书的流程很简单: 生成ca私钥(ca.key) 使用ca私钥生成ca证书(ca.crt) 生成服务器私钥(server.key) 生成服务器证书签名请求(server.csr) 使用ca证书签名服务器证书(server.crt) 生成客户端私钥(client.key) 生成客户端证书签名请求(client.csr) 使用ca证书签名客户端证书(client.crt) (可选)将客户端的私钥和证书生成客户端p12,这一步是方便将客户端的私钥和证书发送给客户端使用(client.p12) 各个文件的作用: ca.key: 1:用来生成ca证书. 2:结合ca.crt 用来签名服务器和客户端证书car.crt: 1:结合ca.key用来签名服务器和客户端证书 2: 在服务端和客户端交互的过程中,判断对方发过来的证书是否由自己签名生成的server.key: 1.解密客户端用server.crt加密的信息server.crt: 发送给客户端,用来加密信息,客户端使用ca.crt验证client.key: 1.解密服务端用client.crt加密的信息clien.crt: 发送给服务端,用来加密信息,服务端使用ca.crt验证 p12: 里面包含了客户端的私钥和证书,客户端拿到p12文件后,将里面的内容解析成,client.key和client.crt. 其中证书可能有不同的格式.但是基本上都是X.509标准的.所以网上可能会有生成,.pem,.der,.p12文件.其实原理大同小异.只要区分好私钥,证书就理解其中原理.","link":"/2024/10/19/tls-introdution/"},{"title":"使用asdf管理你的sdk","text":"对于我这种使用多种语言开发,并且可能在给个版本之前来回切换的人来说,一直渴望一个好的sdk管理工具举个具体的例子:有两个项目,一个项目使用jdk-8另一个项目使用jdk-17,在ide里面还好说,毕竟可选择,但是当你在命令行里面操作时,来回切换jdk有多难受就不必我多说了吧而且如果要用两个jdk,这两个就要使用HomeBrew安装两个jdk,而且安装的路径还不一样 除此之外,还有前端的node版本,不同的项目使用的NodeJs版本不同,换来换区也是麻烦的不行 这个时候就体现了asdf这个工具的方便之处, 如果使用来asdf,那么安装和切换jdk的版本就会如此美妙 现在假设在使用asdf的情况下,如果有两个项目a 和 b,分别使用jdk-8和jdk-17,那么管理的流程就是如下的 安装对应的jdk:asdf install java openjdk-8, asdf install java openjdk-17 分别进入a和b两个目录,执行asdf local java openjdk-8,asdf local java openjdk-17 这个时候,当你在命令行进入对应的项目,你执行java -version就会对应不同的jdk版本 而且安装的jdk统一的都在~/.asdf.plugins/java目录下,丝毫不会污染你其他的目录,干净又卫生了属于是 下面简单说下安装以及使用,基本上是官方文档内容 安装我是使用HomeBrew安装 123brew install asdfecho -e &quot;\\n. $(brew --prefix asdf)/libexec/asdf.sh&quot; &gt;&gt; ${ZDOTDIR:-~}/.zshrc 使用(以java为例)plugin在asdf的语义中,plugin就是帮你管理对应语言sdk的模块,比如你需要下载是管理java的版本,你就需要下载对应的java plugin 搜索plugin1asdf plugin list all | grep java 安装plugin1asdf plugin add java 安装sdk12345678910# 搜索jdkasdf list all java | grep jdk # 安装jdk # 安装指定版本asdf install java openjdk-17.0 # 安装指定版本的最新版本asdf install java openjdk-17:latest # 安装最新稳定版asdf install java latest 设置1234# 设置命令行使用的版本asdf global java openjdk-17# 设置当前路径使用的jdk版本,会在当前目录下生成一个.tool-versions文件asdf local java openjdk-17 其他常用命令12345678910111213141516# 查看当前各个sdk的版本asdf current# 查看当前java使用的sdk版本asdf current java# 查看安装那些pluginasdf plugin list# 查看当前使用的java 命令的路径asdf which java# 查看当前使用的java sdk的路径asdf where java# 移除对应的sdkasdf uninstall java openjdk-17# 移除对应的pluginasdf plugin remove java# 更新(所有)pluginasdf plugin update [--all] 参考资料asdf官方文档","link":"/2023/09/26/use-asdf-manage-sdk/"},{"title":"vscode更好用的vim插件","text":"前言对我来说,使用vim后有两个后遗症,一是想把vim配置的全知全能,二是在任何软件中都想启用vim模式,现在前者的症状已经有所减轻,后者愈发严重 更好用的vim插件之前在 vscode中使用的 vim插件一直是vim,但是这个插件有一个让我非常苦恼的问题,就是这个插件没有neovim中的flash插件,它默认的快速移动插件是easymotion,个人觉得,easymotion这个插件的已送快捷键方式实在是太不方便,举个简单的例子:他的prefix是要按两下leader按键,而flash插件就十分的方便,按下s然后输入词就可以快速搜索,这点就是很舒服的地方,下面两个图 flash easy-motion 另外我也没有在vim插件的文档中找到如何更改easymotion的快捷键的地方,如果可以改的话也可以进行配置(我的intellij idea就是通过这个更改实现类flash模式) 而vscode中的neovim插件可以使用neovim的原生插件,这一点就非常舒服了,这个插件的基本原理大概就是:使用vscode去连接一个neovim实例,然后在command和normal模式下,将用户输入的命令直接传给neovim 配置安装就不多说了,有手就行 有一些需要注意的地方是: 需要指定neovim的安装位置 如果需要个性化配置,可以制定一个init.lua/init.vim文件 具体配置选项可以看这里 我的配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172-- _ _-- _ __ | | _ _ __ _ (_) _ __-- | '_ \\ | | | | | | / _` | | | | '_ \\-- | |_) | | | | |_| | | (_| | | | | | | |-- | .__/ |_| \\__,_| \\__, | |_| |_| |_|-- |_| |___/--local lazypath = vim.fn.stdpath(&quot;data&quot;) .. &quot;/lazy/lazy.nvim&quot;if not vim.loop.fs_stat(lazypath) then -- bootstrap lazy.nvim -- stylua: ignore vim.fn.system({ &quot;git&quot;, &quot;clone&quot;, &quot;--filter=blob:none&quot;, &quot;https://github.com/folke/lazy.nvim.git&quot;, &quot;--branch=stable&quot;, lazypath })endvim.opt.rtp:prepend(vim.env.LAZY or lazypath)require('lazy').setup({ { &quot;kylechui/nvim-surround&quot;, version = &quot;*&quot;, -- Use for stability; omit to use `main` branch for the latest features event = &quot;VeryLazy&quot;, config = function() require(&quot;nvim-surround&quot;).setup({ -- Configuration here, or leave empty to use defaults }) end }, { &quot;folke/flash.nvim&quot;, event = &quot;VeryLazy&quot;, ---@type Flash.Config opts = {}, -- stylua: ignore keys = { { &quot;s&quot;, mode = { &quot;n&quot;, &quot;o&quot;, &quot;x&quot; }, function() require(&quot;flash&quot;).jump() end, desc = &quot;Flash&quot; }, { &quot;S&quot;, mode = { &quot;n&quot;, &quot;o&quot;, &quot;x&quot; }, function() require(&quot;flash&quot;).treesitter() end, desc = &quot;Flash Treesitter&quot; }, -- { &quot;r&quot;, mode = &quot;o&quot;, function() require(&quot;flash&quot;).remote() end, desc = &quot;Remote Flash&quot; }, { &quot;R&quot;, mode = { &quot;o&quot;, &quot;x&quot; }, function() require(&quot;flash&quot;).treesitter_search() end, desc = &quot;Treesitter Search&quot; }, { &quot;&lt;c-s&gt;&quot;, mode = { &quot;c&quot; }, function() require(&quot;flash&quot;).toggle() end, desc = &quot;Toggle Flash Search&quot; }, }, }})-- _-- __ __ ___ ___ ___ __| | ___-- \\ \\ / / / __| / __| / _ \\ / _` | / _ \\-- \\ V / \\__ \\ | (__ | (_) | | (_| | | __/-- \\_/ |___/ \\___| \\___/ \\__,_| \\___|---- __ _-- ___ ___ _ __ / _| (_) __ _-- / __| / _ \\ | '_ \\ | |_ | | / _` |-- | (__ | (_) | | | | | | _| | | | (_| |-- \\___| \\___/ |_| |_| |_| |_| \\__, |-- |___/--local map = vim.keymap.setlocal expr_options = { expr = true, silent = true }-- 这里很重要,防止光标到折叠为止,折叠自动展开map(&quot;n&quot;,&quot;k&quot;,&quot;gk&quot;,{remap = true})map(&quot;n&quot;,&quot;j&quot;,&quot;gj&quot;,{remap = true})map('n','zc',&quot;&lt;cmd&gt;call VSCodeCall('editor.fold')&lt;cr&gt;&quot;)map('n','zo',&quot;&lt;cmd&gt;call VSCodeCall('editor.unfold')&lt;cr&gt;&quot;)map('n','zR',&quot;&lt;cmd&gt;call VSCodeCall('editor.unfoldAll')&lt;cr&gt;&quot;)map('n','zM',&quot;&lt;cmd&gt;call VSCodeCall('editor.foldAll')&lt;cr&gt;&quot;)map('n','&lt;leader&gt;e',&quot;&lt;cmd&gt;call VSCodeCall('workbench.action.quickOpenNavigateNextInFilePicker')&lt;cr&gt;&quot;,{remap=true}) 注意 123-- 这里很重要,防止光标到折叠为止,折叠自动展开map(&quot;n&quot;,&quot;k&quot;,&quot;gk&quot;,{remap = true})map(&quot;n&quot;,&quot;j&quot;,&quot;gj&quot;,{remap = true}) 这两句配置很是很重要的,如果不配置,在neovim模式下,光标移动到折叠为止,折叠会自动展开","link":"/2023/09/23/vscode-neovim-plugin/"}],"tags":[{"name":"cicd","slug":"cicd","link":"/tags/cicd/"},{"name":"gitlab","slug":"gitlab","link":"/tags/gitlab/"},{"name":"pipeline","slug":"pipeline","link":"/tags/pipeline/"},{"name":"gradle","slug":"gradle","link":"/tags/gradle/"},{"name":"spring-boot","slug":"spring-boot","link":"/tags/spring-boot/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"ganesha","slug":"ganesha","link":"/tags/ganesha/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"neovim","slug":"neovim","link":"/tags/neovim/"},{"name":"idea","slug":"idea","link":"/tags/idea/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"encode","slug":"encode","link":"/tags/encode/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"macos","slug":"macos","link":"/tags/macos/"},{"name":"Mysql","slug":"Mysql","link":"/tags/Mysql/"},{"name":"proxysql","slug":"proxysql","link":"/tags/proxysql/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"terminal","slug":"terminal","link":"/tags/terminal/"},{"name":"快捷键","slug":"快捷键","link":"/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"name":"tls","slug":"tls","link":"/tags/tls/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"asdf","slug":"asdf","link":"/tags/asdf/"},{"name":"asdf manage","slug":"asdf-manage","link":"/tags/asdf-manage/"}],"categories":[{"name":"cicd","slug":"cicd","link":"/categories/cicd/"},{"name":"gradle","slug":"gradle","link":"/categories/gradle/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"gitlab","slug":"cicd/gitlab","link":"/categories/cicd/gitlab/"},{"name":"ganesha","slug":"ganesha","link":"/categories/ganesha/"},{"name":"neovim奇技淫巧","slug":"neovim奇技淫巧","link":"/categories/neovim%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/"},{"name":"some litttle tricks","slug":"some-litttle-tricks","link":"/categories/some-litttle-tricks/"},{"name":"万物皆可vim","slug":"万物皆可vim","link":"/categories/%E4%B8%87%E7%89%A9%E7%9A%86%E5%8F%AFvim/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"Mysql","slug":"Mysql","link":"/categories/Mysql/"},{"name":"pipeline","slug":"cicd/gitlab/pipeline","link":"/categories/cicd/gitlab/pipeline/"},{"name":"proxysql","slug":"proxysql","link":"/categories/proxysql/"},{"name":"shell","slug":"shell","link":"/categories/shell/"},{"name":"键指如飞","slug":"键指如飞","link":"/categories/%E9%94%AE%E6%8C%87%E5%A6%82%E9%A3%9E/"},{"name":"tls","slug":"tls","link":"/categories/tls/"},{"name":"效率工具","slug":"效率工具","link":"/categories/%E6%95%88%E7%8E%87%E5%B7%A5%E5%85%B7/"}],"pages":[]}